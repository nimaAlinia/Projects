{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1) Offline Part**"
      ],
      "metadata": {
        "id": "ZppvQV7EAb0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPgkDnLFus6Y"
      },
      "outputs": [],
      "source": [
        "##############################################  Offline Part ###################################################\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "board_pin_ds_path = \"\"  #path of the board_pin dataset (.json)\n",
        "pin_img_ds_path = \"\"    #path of the pin_image dataset (.json)\n",
        "with open(board_pin_ds_path) as f:\n",
        "    board_pin_ds = json.load(f)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "with open(pin_img_ds_path) as f:\n",
        "    pin_img_ds = json.load(f)\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzdTSiyXX70D"
      },
      "outputs": [],
      "source": [
        "board_IDs_list = list()\n",
        "for board_pin in board_pin_ds:\n",
        "   board_ID = board_pin['board_id']\n",
        "   board_IDs_list.append(board_ID)\n",
        "\n",
        "distinct_board_IDs_list = list(set(board_IDs_list))\n",
        "image_names_list = list()\n",
        "for pin_img in pin_img_ds:\n",
        "   image_name = pin_img['im_name']\n",
        "   image_names_list.append(image_name)\n",
        "\n",
        "distinct_image_names_list = list(set(image_names_list))\n",
        "board_IDs_list.clear();\n",
        "image_names_list.clear();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hZe7giEcaoF"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "g0 = nx.Graph()\n",
        "for img in pin_img_ds:\n",
        "  g0.add_edge(img['im_name'],img['pin_id'])\n",
        "\n",
        "\n",
        "pin_img_ds.clear();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvFYBk6LfWvD"
      },
      "outputs": [],
      "source": [
        "\n",
        "for board_obj in board_pin_ds:\n",
        "  for pin in board_obj['pins'] :\n",
        "      g0.add_edge(board_obj['board_id'],pin)\n",
        "\n",
        "board_pin_ds.clear();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7NhGaHfgou5"
      },
      "outputs": [],
      "source": [
        "#create image-board file\n",
        "image-board-path = \"\"   #select a path to save the image_board edge lists (.txt)\n",
        "f = open(image-board-path, \"w\")\n",
        "\n",
        "g1 = nx.Graph()\n",
        "for img in distinct_image_names_list :\n",
        "  for neighbor in  g0.neighbors(img) :\n",
        "     for x in g0.neighbors(neighbor) :\n",
        "       if x!=img :\n",
        "        f.write(f\"{img} {x}\\n\")\n",
        "        g1.add_edge(img,x)\n",
        "\n",
        "f.close()\n",
        "g0.clear();\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF610zpdgw-R"
      },
      "outputs": [],
      "source": [
        "records = []\n",
        "for board_ID in distinct_board_IDs_list:\n",
        "    records.append([x for x in g1.neighbors(board_ID) if x!=board_ID])\n",
        "\n",
        "g1.clear();\n",
        "distinct_image_names_list.clear()\n",
        "distinct_board_IDs_list.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find Strongly pair Images in the boards  by FpGrowth#\n",
        "from mlxtend.frequent_patterns import fpgrowth , association_rules\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "#Transform List of Lists to DataFrame\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(records).transform(records)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "del te\n",
        "del te_ary"
      ],
      "metadata": {
        "id": "O731QZLHIbty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records.clear()\n",
        "\n",
        "df2= fpgrowth(df, min_support=0.00015, use_colnames=True)\n",
        "\n",
        "del df"
      ],
      "metadata": {
        "id": "8U8nEWkrJdQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_confidence = 0.5\n",
        "min_left = 1\n",
        "\n",
        "rules = association_rules(df2 , metric =\"lift\", min_threshold = 1)\n",
        "\n",
        "del df2\n",
        "\n",
        "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
        "rules = rules[rules['confidence'].apply(lambda x: x > min_confidence) & rules['antecedents'].apply(lambda x: len(x) == 1) & rules['consequents'].apply(lambda x: len(x) == 1)]\n"
      ],
      "metadata": {
        "id": "1DF4Uv3ZKaR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image-image-path = \"\"  #select a path to save the image_image edge lists  (.txt)\n",
        "f = open(image-image-path, \"w\")\n",
        "\n",
        "for index,row in rules.iterrows() :\n",
        "  f.write(f\"{next(iter(row['antecedents']))}  {next(iter(row['consequents']))}\\n\")\n",
        "f.close()"
      ],
      "metadata": {
        "id": "jZeXEY6czoYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Online Part**"
      ],
      "metadata": {
        "id": "u8hvWsIq_vhr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAxjKgbSuhC5"
      },
      "outputs": [],
      "source": [
        "\n",
        "##############################################  Online Part ###################################################\n",
        "\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "image_list = []\n",
        "board_list = []\n",
        "gf1 = nx.Graph()\n",
        "\n",
        "image-board-path = \"\"  #path of the image_board edge lists (.txt)\n",
        "f = open(\"image-board-path\", \"r\")\n",
        "\n",
        "edgeList = f.readlines()\n",
        "for line in edgeList:\n",
        "    nodes = line.split()\n",
        "    gf1.add_edge(nodes[0],nodes[1])\n",
        "    image_list.append(nodes[0])\n",
        "    board_list.append(nodes[1])\n",
        "\n",
        "f.close()\n",
        "\n",
        "image_list = list(set(image_list))\n",
        "board_list = list(set(board_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "\n",
        "cat_itr_dict = {}\n",
        "board-category-path = \"\"  #path of the board_category dataset (.json)\n",
        "with open(board-category-path) as f:\n",
        "    board_cate_ds = json.load(f)\n",
        "    f.close()\n",
        "\n",
        "cat_list = []\n",
        "\n",
        "gf_board_cat = nx.Graph()\n",
        "for board_cat in board_cate_ds :\n",
        "  gf_board_cat.add_edge(board_cat['board_id'] , board_cat['cate_id'])\n",
        "  cat_list.append(board_cat['cate_id'])\n",
        "\n",
        "\n",
        "\n",
        "cat_list = list(set(cat_list))\n",
        "\n",
        "for cat in cat_list :\n",
        "  cat_itr_dict[cat] = 0\n",
        "\n",
        "\n",
        "cat_itr_dict = dict(sorted(cat_itr_dict.items()))\n"
      ],
      "metadata": {
        "id": "GjStu1eJHOy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9kUY1PFzXzH"
      },
      "outputs": [],
      "source": [
        "\n",
        "image-image-path = \"\"  #path of the image_image edge lists (.txt)\n",
        "gf2 = nx.read_edgelist(image-image-path,create_using=nx.DiGraph(), nodetype = str)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_walk(graph1,q,alpha,N):\n",
        "\n",
        "    random_walk_list = []\n",
        "\n",
        "    currPin = q\n",
        "    steps = 0\n",
        "    walk = [q]\n",
        "\n",
        "\n",
        "    stop = False\n",
        "    while(1):\n",
        "\n",
        "\n",
        "      if(currPin==q) :\n",
        "         currBoard = random.choice([n for n in graph1.neighbors(currPin) if len(list(graph1.neighbors(n)))!=1])\n",
        "      else :\n",
        "         currBoard = random.choice([n for n in graph1.neighbors(currPin)])\n",
        "\n",
        "\n",
        "      currPin = random.choice( [n for n in graph1.neighbors(currBoard) if n!=q])\n",
        "\n",
        "      walk.append(currPin)\n",
        "      steps = steps + 1\n",
        "\n",
        "\n",
        "\n",
        "      if(steps >= N):\n",
        "        stop = True\n",
        "        random_walk_list.append(walk)\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "      if random.random()<alpha:\n",
        "        currPin = q\n",
        "        random_walk_list.append(walk)\n",
        "        walk = [q]\n",
        "\n",
        "    return random_walk_list;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R_Jt3dWwAVsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ER-qurDrZqpC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def random_walk(walk_list,q,N,np,nv):\n",
        "\n",
        "\n",
        "\n",
        "    visit_dict = {}\n",
        "    n_High_visited = 0\n",
        "    for image in image_list :\n",
        "      visit_dict[image] = 0\n",
        "\n",
        "    currPin = q\n",
        "    steps = 0\n",
        "\n",
        "    stoping = False\n",
        "    for walk in walk_list:\n",
        "      for w in walk :\n",
        "\n",
        "        if(w!=q) :\n",
        "\n",
        "          steps = steps + 1\n",
        "          visit_dict[w] =  visit_dict[w] + 1\n",
        "\n",
        "\n",
        "\n",
        "          if(visit_dict[w]==nv):\n",
        "            n_High_visited = n_High_visited + 1\n",
        "\n",
        "\n",
        "\n",
        "          if(steps>= N or n_High_visited>=np):\n",
        "            stoping = True\n",
        "            break\n",
        "\n",
        "      if(stoping):\n",
        "        break\n",
        "\n",
        "    return visit_dict,steps;\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "\n",
        "def quick_random_walk(walk_list ,q,N,np,nv,graph2,gama):\n",
        "\n",
        "\n",
        "\n",
        "    visit_dict = {}\n",
        "    n_High_visited = 0\n",
        "    for image in image_list :\n",
        "      visit_dict[image] = 0\n",
        "\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "    stoping = False\n",
        "    for walk in walk_list:\n",
        "      for w in walk :\n",
        "        delta = 1000\n",
        "        if(w!=q) :\n",
        "\n",
        "          steps = steps + 1\n",
        "\n",
        "          last_visit_number_query = visit_dict[w]\n",
        "\n",
        "          visit_dict[w] =  visit_dict[w] + 1\n",
        "\n",
        "          if(w in graph2.nodes()):\n",
        "            neighbor_count =len(list(graph2.neighbors(w)))\n",
        "            for neighbor in graph2.neighbors(w):\n",
        "              if(neighbor == q):\n",
        "                continue\n",
        "\n",
        "              last_visit_number_neighbor = visit_dict[neighbor]\n",
        "              if(neighbor_count>1):\n",
        "                delta = (1/math.log2(neighbor_count))\n",
        "              if(delta > gama):\n",
        "                delta = gama\n",
        "\n",
        "              delta = gama\n",
        "              visit_dict[neighbor] = round(visit_dict[neighbor] + delta,1)\n",
        "              if(visit_dict[neighbor]>=nv and last_visit_number_neighbor<nv):\n",
        "                n_High_visited = n_High_visited + 1\n",
        "\n",
        "\n",
        "\n",
        "          if(visit_dict[w]>=nv and last_visit_number_query<nv):\n",
        "             n_High_visited = n_High_visited + 1\n",
        "\n",
        "\n",
        "\n",
        "          if(steps>= N or n_High_visited>=np):\n",
        "            stoping = True\n",
        "            break\n",
        "      if(stoping):\n",
        "        break\n",
        "\n",
        "    return visit_dict,steps;\n",
        "\n"
      ],
      "metadata": {
        "id": "tCCnn5djJ6RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjkuuPYJnIY_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def pixie_randomwalk_multiple_query(walk_list,query_set,weight_set,graph1,N,Np,Nv):\n",
        "  max_degree = max([d for n, d in graph1.degree(image_list)])\n",
        "  V = {}\n",
        "  Vq = []\n",
        "  sq = []\n",
        "  sigma_sq = 0\n",
        "\n",
        "  pixie_total_step  = 0\n",
        "\n",
        "\n",
        "  for i in range(len(query_set)) :\n",
        "    query_degree = 0\n",
        "    query_degree =  graph1.degree(query_set[i])\n",
        "\n",
        "    res = query_degree * (max_degree - math.log(query_degree,2))\n",
        "\n",
        "    sq.append(res)\n",
        "    sigma_sq = sigma_sq + sq[i]\n",
        "\n",
        "\n",
        "  for i in range(len(query_set)) :\n",
        "     Nq = math.floor(weight_set[i] * N * sq[i] / sigma_sq)\n",
        "\n",
        "     result , total_step = random_walk(walk_list[i],query_set[i],Nq,Np,Nv)\n",
        "     Vq.append(result)\n",
        "     pixie_total_step = pixie_total_step + total_step\n",
        "\n",
        "\n",
        "  for image in image_list:\n",
        "    sum = 0\n",
        "    for i in range(len(query_set)) :\n",
        "      sum = sum +  math.sqrt(Vq[i][image])\n",
        "    V[image] = math.pow(sum,2)\n",
        "\n",
        "\n",
        "  V = dict(sorted(V.items(), key=lambda item: item[1],reverse=True))\n",
        "\n",
        "  return V,pixie_total_step;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poAKnFeSkmJS"
      },
      "outputs": [],
      "source": [
        "\n",
        "def quick_pixie_randomwalk_multiple_query(walk_list,query_set,weight_set,graph1,N,Np,Nv,graph2,gama):\n",
        "  max_degree = max([d for n, d in graph1.degree(image_list)])\n",
        "  V = {}\n",
        "  Vq = []\n",
        "  sq = []\n",
        "  query_degree = []\n",
        "  sigma_sq = 0\n",
        "\n",
        "  quick_pixie_total_step = 0\n",
        "\n",
        "  for i in range(len(query_set)) :\n",
        "    query_degree.append( graph1.degree(query_set[i]))\n",
        "\n",
        "    res = query_degree[i] * (max_degree - math.log(query_degree[i],2))\n",
        "\n",
        "    sq.append(res)\n",
        "    sigma_sq = sigma_sq + sq[i]\n",
        "\n",
        "\n",
        "  for i in range(len(query_set)) :\n",
        "     Nq = math.floor(weight_set[i] * N * sq[i] / sigma_sq)\n",
        "\n",
        "     result,total_step = quick_random_walk(walk_list[i],query_set[i],Nq,Np,Nv,graph2,gama)\n",
        "     Vq.append(result)\n",
        "     quick_pixie_total_step = quick_pixie_total_step + total_step\n",
        "\n",
        "\n",
        "  for image in image_list:\n",
        "    sum = 0\n",
        "    for i in range(len(query_set)) :\n",
        "      sum = sum +  math.sqrt(Vq[i][image])\n",
        "    V[image] = math.pow(sum,2)\n",
        "\n",
        "  V = dict(sorted(V.items(), key=lambda item: item[1],reverse=True))\n",
        "  return V,quick_pixie_total_step\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blsXSxyE7Kdg"
      },
      "outputs": [],
      "source": [
        "# ( First Comprision)  calculate jacard index\n",
        "def calculate_jaccard_index(first, second):\n",
        "     jacard_index = len(set(first).intersection(second)) / len(set(first).union(second))\n",
        "     return jacard_index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#( second Comprision) jacard distance with query list\n",
        "def category_Index(image_list,img_board_graph,board_cat_graph):\n",
        "  image_cate_set = set()\n",
        "  for img in image_list :\n",
        "    board_list = list(gf1.neighbors(img))\n",
        "    for board in board_list :\n",
        "      cats = list(gf_board_cat.neighbors(board))[0]\n",
        "      image_cate_set.add(cats)\n",
        "  return list(image_cate_set)\n",
        "\n",
        "def calculate_category_index(q_list,pixie_im_list,q_pixie_im_list,img_board_graph,board_cat_graph) :\n",
        "  query_cat = category_Index(q_list,img_board_graph,board_cat_graph)\n",
        "  pixie_keys_cat = category_Index(pixie_im_list,img_board_graph,board_cat_graph)\n",
        "  quick_pixie_keys_cat = category_Index(q_pixie_im_list,img_board_graph,board_cat_graph)\n",
        "\n",
        "  jacard_index_cat1 = calculate_jaccard_index(pixie_keys_cat,query_cat)\n",
        "  jacard_index_cat2 = calculate_jaccard_index(quick_pixie_keys_cat,query_cat)\n",
        "  return jacard_index_cat1,jacard_index_cat2\n"
      ],
      "metadata": {
        "id": "oa_G6IgKLM3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#( Thirth Comprision)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def weighted_category_count(image_list,weight_list,img_board_graph,board_cat_graph):\n",
        "\n",
        "  if weight_list == 0:\n",
        "    weight_list = [1 for _ in range(len(image_list))]\n",
        "\n",
        "  image_cate_list = list()\n",
        "  for i in range(len(image_list)) :\n",
        "\n",
        "    board_list = list(img_board_graph.neighbors(image_list[i]))\n",
        "    for board in board_list :\n",
        "      cats = [y for y in board_cat_graph.neighbors(board)]\n",
        "      result = dict(Counter(cats))\n",
        "      for key,value in result.items() :\n",
        "         cat_itr_dict[key] =  float(cat_itr_dict[key]) + (value*weight_list[i])\n",
        "\n",
        "\n",
        "\n",
        "  result = cat_itr_dict.copy()\n",
        "\n",
        "\n",
        "  for key in cat_itr_dict.keys() :\n",
        "    cat_itr_dict[key] = 0\n",
        "\n",
        "  return result\n",
        "\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "\n",
        "def cosine_similarity(first_list,second_list):\n",
        "  cos_sim = dot(first_list, second_list)/(norm(first_list)*norm(second_list))\n",
        "  return cos_sim;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_Cosine_similarity(q_list,pixie_im_list,q_pixie_im_list ,q_weight_list,\n",
        "                                img_board_graph,board_cat_graph):\n",
        "\n",
        "  cc1 = weighted_category_count(query_list,weight_list,img_board_graph,board_cat_graph)\n",
        "  cc2 = weighted_category_count(pixie_keys,0,img_board_graph,board_cat_graph)\n",
        "  cc3 = weighted_category_count(quick_pixie_keys,0,img_board_graph,board_cat_graph)\n",
        "\n",
        "  cosine_pixie_query = cosine_similarity(list(cc1.values()),list(cc2.values()))\n",
        "\n",
        "  cosine_q_pixie_query = cosine_similarity(list(cc1.values()),list(cc3.values()))\n",
        "\n",
        "\n",
        "  return cosine_pixie_query,cosine_q_pixie_query\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PO5q9h0NVCN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with open('/content/drive/MyDrive/Pixie/Results.csv', 'w', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      field = [\"minSup\", \"minConf\", \"N\", \"Np\" ,\"Nv\",\n",
        "              \"gama\",\"alpha\",\"top_k\",\"min_weight\",\"max_weight\",\n",
        "              \"query_list_length\",\"pixie_quickPixie_JI\",\"pixie_query_JI\",\"quick_pixie_query_JI\",\"pixie_CS\",\"quick_pixie_CS\",\n",
        "              \"total_step_distance\"]\n",
        "\n",
        "      writer.writerow(field)\n",
        "'''"
      ],
      "metadata": {
        "id": "TnLqSsTbhvup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import csv\n",
        "\n",
        "def Write_Result_in_CSV(sup, conf , N , np , nv , gama , alpha , top_k , min_weight , max_weight , query_list_length , Avg_jac_Index , Avg_jacard_index_cat1 , Avg_jacard_index_cat2 , Avg_co1 , Avg_co2 , Avg_total_step_distance) :\n",
        "\n",
        "  with open('/content/drive/MyDrive/Pixie/Results.csv', 'a', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      field = [\"minSup\", \"minConf\", \"N\", \"Np\" ,\"Nv\",\n",
        "              \"gama\",\"alpha\",\"top_k\",\"min_weight\",\"max_weight\",\n",
        "              \"query_list_length\",\"pixie_query_JI\",\"quick_pixie_query_JI\",\"pixie_CS\",\"quick_pixie_CS\",\n",
        "              \"total_step_distance\"]\n",
        "\n",
        "      writer.writerow([sup, conf , N , np , nv ,\n",
        "                      gama , alpha , top_k , min_weight , max_weight ,\n",
        "                      query_list_length , Avg_jac_Index , Avg_jacard_index_cat1 , Avg_jacard_index_cat2 , Avg_co1 , Avg_co2 ,\n",
        "                      Avg_total_step_distance])\n",
        "'''\n"
      ],
      "metadata": {
        "id": "a25hIfSAr6-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1sntxaxTPaV"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "sup = 0.00015\n",
        "conf = 0.5\n",
        "N = 10000\n",
        "np = 50\n",
        "nv = 100\n",
        "top_k = 10\n",
        "alpha = 0.2\n",
        "min_weight = 1\n",
        "max_weight = 2\n",
        "query_list_length = 10\n",
        "\n",
        "\n",
        "\n",
        "query_list = random.sample(image_list,query_list_length)\n",
        "\n",
        "#print(query_list)\n",
        "\n",
        "weight_list = set()\n",
        "while(len(weight_list)<=query_list_length) :\n",
        "  weight_list.add(random.uniform(min_weight,max_weight))\n",
        "\n",
        "weight_list = list(sorted(weight_list,reverse=True))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_step_distance_list = list()\n",
        "jac_Index_list = list()\n",
        "jacard_index_cat1_list =  list()\n",
        "jacard_index_cat2_list =  list()\n",
        "co1_list = list()\n",
        "co2_list = list()\n",
        "\n",
        "gama_list = [x/10 for x in range(0,11)]\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs) :\n",
        "\n",
        "  print(f\"------------------------- epoch = {epoch+1} -------------------------------------------\")\n",
        "\n",
        "  pixie_total_step = 0\n",
        "  quick_pixie_total_step = 0\n",
        "\n",
        "  total_step_distance_for_gama = dict()\n",
        "  jac_Index_for_gama = dict()\n",
        "  jacard_index_cat1_for_gama =  dict()\n",
        "  jacard_index_cat2_for_gama =  dict()\n",
        "  co1_for_gama = dict()\n",
        "  co2_for_gama = dict()\n",
        "\n",
        "  random_walk_list_for_queryList = []\n",
        "  for q in query_list :\n",
        "    random_walk_list_for_queryList.append(generate_random_walk(gf1,q,alpha,N))\n",
        "\n",
        "\n",
        "  V1,pixie_total_step = pixie_randomwalk_multiple_query(random_walk_list_for_queryList,query_list,weight_list,gf1,N,np,nv)\n",
        "  V1 = dict(itertools.islice(V1.items(), top_k))\n",
        "  #print(V1)\n",
        "\n",
        "  for gama in gama_list :\n",
        "\n",
        "\n",
        "    print(\"-----------------------------------------------------------------------------\")\n",
        "    print(f\"-------------------------gama = {gama} ----------------------------------------\")\n",
        "    V2,quick_pixie_total_step = quick_pixie_randomwalk_multiple_query(random_walk_list_for_queryList,query_list,weight_list,gf1,N,np,nv,gf2,gama)\n",
        "    V2 = dict(itertools.islice(V2.items(), top_k))\n",
        "\n",
        "    pixie_keys = list(V1.keys())\n",
        "    quick_pixie_keys = list(V2.keys())\n",
        "\n",
        "    total_step_distance = pixie_total_step - quick_pixie_total_step\n",
        "    total_step_distance_for_gama[gama] = total_step_distance\n",
        "\n",
        "\n",
        "    jac_Index = calculate_jaccard_index(pixie_keys,quick_pixie_keys)\n",
        "    jac_Index_for_gama[gama] = jac_Index\n",
        "\n",
        "    jacard_index_cat1,jacard_index_cat2 = calculate_category_index(query_list,pixie_keys,quick_pixie_keys,gf1,gf_board_cat)\n",
        "    jacard_index_cat1_for_gama[gama] =  jacard_index_cat1\n",
        "    jacard_index_cat2_for_gama[gama] =  jacard_index_cat2\n",
        "\n",
        "    co1,co2 = calculate_Cosine_similarity(query_list,pixie_keys,quick_pixie_keys ,weight_list,gf1,gf_board_cat)\n",
        "    co1_for_gama[gama] = co1\n",
        "    co2_for_gama[gama] = co2\n",
        "\n",
        "    #print(V2)\n",
        "\n",
        "\n",
        "    print(f\"pixie_total_step  = {pixie_total_step}\")\n",
        "    print(f\"quick_pixie_total_step  = {quick_pixie_total_step}\")\n",
        "\n",
        "    print(f\"total_step_distance = {total_step_distance}\")\n",
        "\n",
        "\n",
        "    print(\"--------------------------Metric1----------------------------------------\")\n",
        "\n",
        "\n",
        "    print(f\"jacard index = {jac_Index}\")\n",
        "\n",
        "    print(\"--------------------------Metric2----------------------------------------\")\n",
        "\n",
        "    print(f\"jacard index cat1 = {jacard_index_cat1}\")\n",
        "    print(f\"jacard index cat2 = {jacard_index_cat2}\")\n",
        "\n",
        "    print(\"--------------------------Metric3----------------------------------------\")\n",
        "\n",
        "\n",
        "    print(f\"pixie_query cosine similarity = {co1}\")\n",
        "    print(f\"quick_pixie_query cosine similarity = {co2}\")\n",
        "\n",
        "    print(\"\\n\\n******************************************************************************\")\n",
        "\n",
        "\n",
        "  total_step_distance_list.append(total_step_distance_for_gama)\n",
        "  jac_Index_list.append(jac_Index_for_gama)\n",
        "  jacard_index_cat1_list.append(jacard_index_cat1_for_gama)\n",
        "  jacard_index_cat2_list.append(jacard_index_cat2_for_gama)\n",
        "  co1_list.append(co1_for_gama)\n",
        "  co2_list.append(co2_for_gama)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for g in gama_list :\n",
        "\n",
        "  sum_total_step_distance = 0\n",
        "  sum_jac_Index = 0\n",
        "  sum_jacard_index_cat1 = 0\n",
        "  sum_jacard_index_cat2 = 0\n",
        "  sum_co1 = 0\n",
        "  sum_co2 = 0\n",
        "\n",
        "  for i in range(epochs) :\n",
        "    sum_total_step_distance = sum_total_step_distance + total_step_distance_list[i][g]\n",
        "    sum_jac_Index = sum_jac_Index + jac_Index_list[i][g]\n",
        "    sum_jacard_index_cat1 = sum_jacard_index_cat1 + jacard_index_cat1_list[i][g]\n",
        "    sum_jacard_index_cat2 = sum_jacard_index_cat2 + jacard_index_cat2_list[i][g]\n",
        "    sum_co1 = sum_co1 + co1_list[i][g]\n",
        "    sum_co2 = sum_co2 + co2_list[i][g]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  Avg_total_step_distance = sum_total_step_distance/epochs\n",
        "  Avg_jac_Index = sum_jac_Index/epochs\n",
        "  Avg_jacard_index_cat1 = sum_jacard_index_cat1/epochs\n",
        "  Avg_jacard_index_cat2 = sum_jacard_index_cat2/epochs\n",
        "  Avg_co1 = sum_co1/epochs\n",
        "  Avg_co2 = sum_co2/epochs\n",
        "\n",
        "\n",
        "  print(f\"-------------------------------------------------------------------------------------------\")\n",
        "  print(f\"--------------------------Averages for gama = {g} ----------------------------------------\")\n",
        "\n",
        "  print(f\"Avg_total_step_distance = {Avg_total_step_distance}\")\n",
        "\n",
        "  print(f\"--------------------------Average Metric1 for gama = {g} ----------------------------------------\")\n",
        "  print(f\"Avg_ jacard index = {Avg_jac_Index}\")\n",
        "\n",
        "  print(f\"--------------------------Average Metric2 for gama = {g} ----------------------------------------\")\n",
        "\n",
        "  print(f\"Avg_jacard_index_cat1 = {Avg_jacard_index_cat1}\")\n",
        "  print(f\"Avg_jacard_index_cat2 = {Avg_jacard_index_cat2}\")\n",
        "\n",
        "  print(f\"--------------------------Average Metric3  for gama = {g} ----------------------------------------\")\n",
        "\n",
        "\n",
        "  print(f\"Avg_pixie_query cosine similarity = {Avg_co1}\")\n",
        "  print(f\"Avg_quick_pixie_query cosine similarity = {Avg_co2}\")\n",
        "\n",
        "  #Write_Result_in_CSV(sup, conf , N , np , nv , g , alpha , top_k , min_weight , max_weight , query_list_length , Avg_jac_Index , Avg_jacard_index_cat1 , Avg_jacard_index_cat2 , Avg_co1 , Avg_co2 , Avg_total_step_distance)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
